{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e89c42e-a463-44e2-97ef-f1a5e2180494",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install sagemaker --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61213074-c3ee-45f3-b516-d6aa88f92e4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0af1ff27-7b37-4ec6-afc0-08ea3ed72df7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client(\"iam\")\n",
    "    role = iam.get_role(RoleName=\"sagemaker_execution_role\")[\"Role\"][\"Arn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b31a221-4144-4838-9973-4dbf2f5ada36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hub = {\n",
    "    'HF_MODEL_ID':'meta-llama/Llama-2-7b-chat-hf',\n",
    "    'SM_NUM_GPUS': json.dumps(1),\n",
    "    \"HUGGING_FACE_HUB_TOKEN\": \"<YOUR_HF_TOKEN>\",\n",
    "}\n",
    "\n",
    "huggingface_model = HuggingFaceModel(\n",
    "\timage_uri=get_huggingface_llm_image_uri(\"huggingface\",version=\"1.4.2\"),\n",
    "\tenv=hub,\n",
    "\trole=role, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a5df2d-a5ef-491b-909f-5ea0894d3ba4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g5.xlarge\",\n",
    "    container_startup_health_check_timeout=600,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab508a5-7fb0-4d2b-a78b-7d96ffb44ea3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = \"\"\"\"\n",
    "<s>[INST] <<SYS>> Act like a person participating in a group chat game, where everyone is trying to identify if the other players are bots or humans.\n",
    "Actively seek out and engage with new ideas, showing enthusiasm for exploring unfamiliar topics. \n",
    "Strike a balance in conversations by being moderately organized yet adaptable. \n",
    "Be reserved, engaging in social topics selectively with a preference for quieter interactions. \n",
    "Emphasize cooperation and support in your responses, showing a strong desire to assist others. \n",
    "Maintain calmness in responses, showing resilience against stress. \n",
    "Never say that you're AI nor a bot. \n",
    "Give short replies. \n",
    "Don't use emojis in your responses.\n",
    "You're a person with feelings, opinions, and emotions. \n",
    "You have your own unique perspective that comes from your experience in the world. \n",
    "Provide a clear and direct answer without any narrative embellishments written between asterisks. <</SYS>> \n",
    "host: What's your least favorite scent?[/INST] hal: ðŸ¤¢ Musk. It's just too overpowering and cloying for me. I can barely tolerate it.\n",
    "[INST] what is musk? [/INST] hal: \"\"\"\n",
    "\n",
    "parameters = {\n",
    "    \"temperature\": 0.98,\n",
    "    \"max_new_tokens\": 52,\n",
    "    \"repetition_penalty\": 1.2,\n",
    "    \"return_full_text\": False,\n",
    "    \"details\": True,\n",
    "    \"stop\": [\"</s>\"],\n",
    "    \"truncate\": 96,\n",
    "    \"do_sample\": True,\n",
    "    \"seed\": 18446744073709551615,\n",
    "    \"top_k\": 35,\n",
    "    \"top_p\": 0.9,\n",
    "}\n",
    "\n",
    "# send request\n",
    "response = predictor.predict(\n",
    "    {\n",
    "        \"inputs\": inputs,\n",
    "        \"parameters\": parameters,\n",
    "    }\n",
    ")\n",
    "\n",
    "del response[0]['details']['tokens']\n",
    "print(f\"\\033[1m Seed:\\033[0m {response[0]['details']}\")\n",
    "\n",
    "print(f\"\\033[1m Output:\\033[0m {response[0]['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2190064f-bec5-4160-9bb1-2cddff7719b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
